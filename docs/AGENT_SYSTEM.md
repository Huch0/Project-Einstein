# Agent-Driven Simulation System

## ğŸ¯ Overview

Project Einstein now features a **GPT-5 Tool-Using Agent** that orchestrates the entire physics simulation pipeline through natural language interaction. Each **SimulationBox** maintains its own conversation context with the agent, enabling personalized, iterative refinement of simulations.

## ğŸ—ï¸ Architecture

### Backend: Agent Tool System

```
backend/app/agent/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ segment_image.py       # SAM segmentation wrapper
â”‚   â”œâ”€â”€ label_segments.py      # GPT Vision entity recognition
â”‚   â”œâ”€â”€ validate_entities.py   # Scene type resolver
â”‚   â”œâ”€â”€ build_scene.py         # Scene JSON builder
â”‚   â”œâ”€â”€ simulate_physics.py    # Matter.js/analytic wrapper
â”‚   â””â”€â”€ analyze_results.py     # Physics analysis + insights
â”œâ”€â”€ tool_registry.py           # OpenAI function schema registry
â”œâ”€â”€ agent_context.py           # Conversation state management
â””â”€â”€ labeler.py                 # (existing) Labeling logic

backend/app/routers/
â””â”€â”€ agent.py                   # POST /agent/chat endpoint
```

### Frontend: SimulationBox Integration

```
frontend/src/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ agent-api.ts           # Agent API client
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ use-simulation-box-agent.ts  # Per-box agent hook
â”œâ”€â”€ components/simulation/
â”‚   â””â”€â”€ agent-chat-panel.tsx   # Natural language chat UI
â””â”€â”€ whiteboard/components/
    â””â”€â”€ simulation-box-node.tsx  # Agent-enabled SimulationBox
```

## ğŸ”„ Agent Workflow

### 1. Upload Image â†’ Full Pipeline

```typescript
// User uploads image to SimulationBox
uploadImage(file)

// Agent orchestrates:
1. segment_image(image_data)
   â†’ Returns: segments with bbox + polygon_px
   
2. label_segments(segments, context="physics diagram")
   â†’ Returns: entities [{segment_id, type, props}]
   
3. validate_scene_entities(entities)
   â†’ Returns: scene_kind="pulley.single_fixed_v0", warnings
   
4. build_physics_scene(segments, entities, mapping)
   â†’ Returns: Scene JSON with bodies + constraints
   
5. simulate_physics(scene, engine="matter-js", duration=5s)
   â†’ Returns: 312 frames with positions over time
   
6. analyze_simulation(frames, scene)
   â†’ Returns: acceleration, energy conservation, motion summary
```

### 2. Natural Language Interaction

```typescript
// User asks questions
sendMessage("What is the system acceleration?")
â†’ Agent: "The system accelerates at 1.96 m/sÂ². Mass B (6kg) descends..."

// User modifies parameters
sendMessage("Increase mass A to 5kg")
â†’ Agent: Calls build_physics_scene + simulate_physics with updated mass
â†’ Returns new frames

// User inspects physics
inspectSimulation()
â†’ Agent: Calls analyze_simulation
â†’ Returns: "Energy conserved within 0.1%, no constraint violations"
```

## ğŸ¨ UI Features

### SimulationBox Header

- **Upload Button** ğŸ“¤: Upload diagram â†’ agent auto-processes
- **Inspect Button** ğŸ§ª: Analyze current simulation (energy, constraints)
- **Chat Button** ğŸ’¬: Open natural language chat panel
- **State Badge**: Shows scene_kind or entity count
- **Loading Overlay**: "Agent processing..." during tool calls
- **Error Display**: Red banner for failures

### Agent Chat Panel

- **Message History**: User â†” Agent conversation
- **Natural Language Input**: Ask anything about the simulation
- **Quick Actions**:
  - "Acceleration?" â†’ Get system acceleration
  - "Energy Check" â†’ Check conservation
  - "Modify Mass" â†’ Change parameters
- **Auto-scroll**: Latest messages always visible
- **Typing Indicator**: Animated dots while agent thinks

## ğŸ“¡ API Endpoints

### POST `/agent/chat`

Orchestrate simulation pipeline via natural language.

**Request:**
```json
{
  "message": "Simulate this pulley diagram",
  "conversation_id": "abc-123",  // optional
  "attachments": [{
    "type": "image",
    "data": "data:image/png;base64,..."
  }]
}
```

**Response:**
```json
{
  "assistant_message": "I found a pulley system with masses 3kg and 6kg...",
  "conversation_id": "abc-123",
  "tool_calls": [
    {"name": "segment_image", "result": {...}},
    {"name": "label_segments", "result": {...}},
    ...
  ],
  "state": {
    "segments_count": 4,
    "entities_count": 3,
    "scene_kind": "pulley.single_fixed_v0",
    "has_scene": true,
    "frames_count": 312
  }
}
```

### GET `/agent/context/{conversation_id}`

Retrieve full conversation state (messages, tool calls, segments, entities, scene, frames).

### DELETE `/agent/context/{conversation_id}`

Reset conversation and clear state.

## ğŸ§ª Tool Registry

Each tool has strict Pydantic schemas for input/output validation:

| Tool | Input | Output |
|------|-------|--------|
| `segment_image` | image_data, mode, sam_url | segments, image metadata |
| `label_segments` | segments, context, use_vision | entities (v0.2 format) |
| `validate_scene_entities` | entities, allow_incomplete | valid, scene_kind, warnings |
| `build_physics_scene` | segments, entities, mapping | Scene JSON, warnings |
| `simulate_physics` | scene, engine, duration | frames, energy, summary |
| `analyze_simulation` | frames, scene, analysis_type | energy/constraints/motion |

Tools are automatically converted to OpenAI function calling format via `tool_registry.get_openai_function_schemas()`.

## ğŸ”’ Conversation State

Each SimulationBox maintains isolated state:

```typescript
interface ConversationContext {
  conversation_id: string;
  image_id?: string;
  segments: Array<Segment>;
  entities: Array<Entity>;
  scene_kind?: string;
  scene?: Scene;
  frames: Array<Frame>;
  messages: Array<Message>;  // Chat history
  tool_calls: Array<ToolCall>;  // Execution log
}
```

## ğŸš€ Usage Example

```typescript
// 1. Create SimulationBox
const box = createSimulationBox();

// 2. Upload diagram
const file = /* user file */;
await uploadImage(file);

// Agent automatically:
// - Segments image (SAM)
// - Labels entities (GPT Vision)
// - Validates scene type
// - Builds Scene JSON
// - Simulates physics (Matter.js)
// - Returns frames for visualization

// 3. Ask questions
await sendMessage("Why does mass B move faster?");
â†’ "Mass B (6kg) is heavier than mass A (3kg), creating net force..."

// 4. Modify and re-simulate
await sendMessage("Set friction to 0.3");
â†’ Agent rebuilds scene with mu_k=0.3, re-simulates

// 5. Inspect results
await inspectSimulation();
â†’ "Energy drift: 0.08% (excellent), Max rope error: 0.001m"
```

## ğŸ§© Integration with Existing Code

### SimulationContext (Legacy)

The original `SimulationContext` (global state) **coexists** with per-box agent contexts:

- **Global**: Dashboard simulation (parseAndBind flow)
- **Per-box**: Whiteboard SimulationBox nodes (agent flow)

### Backward Compatibility

- `/diagram/parse` endpoint **still works** (monolithic)
- Agent tools wrap existing code (SAM detector, builders, physics)
- No breaking changes to existing simulations

## ğŸ“ Testing

```bash
# Backend tool tests
cd backend
pytest tests/test_agent_tools.py -v

# Results:
âœ“ test_validate_scene_entities_pulley
âœ“ test_validate_scene_entities_ramp
âœ“ test_validate_scene_entities_incomplete
âœ“ test_label_segments_stub
```

## ğŸ”® Future Enhancements

- [ ] **Real GPT Vision**: Replace stub labeler with OpenAI Vision API
- [ ] **Multi-turn Editing**: "Move mass A to the left" â†’ regenerate scene
- [ ] **Physics Teaching**: "Explain why tension equals..." â†’ pedagogical insights
- [ ] **Scene Variants**: "What if I remove friction?" â†’ compare scenarios
- [ ] **Export Conversations**: Save chat history + simulation data
- [ ] **Voice Input**: Speak to agent instead of typing

## ğŸ“ Pedagogical Value

The agent system enables:

1. **Exploratory Learning**: Students ask "what if" questions
2. **Iterative Refinement**: Modify parameters without restarting
3. **Conceptual Feedback**: Agent explains physics principles
4. **Error Guidance**: "Mass too light, system won't move" â†’ suggestions
5. **Multi-scenario Comparison**: Track different configurations side-by-side

---

**Agent Tool System: Complete! ğŸ‰**

Each SimulationBox is now a **self-contained physics lab** with an AI teaching assistant.
