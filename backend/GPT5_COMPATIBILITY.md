# GPT-5 API νΈν™μ„± κ°€μ΄λ“

## ν•΄κ²°λ λ¬Έμ 

### 1. β `max_tokens=null` μ—λ¬
**μ¦μƒ:**
```
Error code: 400 - {'error': {'message': "Invalid type for 'max_tokens': 
expected an unsupported value, but got null instead."}}
```

**ν•΄κ²°:**
```python
# Before (μ—λ¬ λ°μƒ)
api_params = {
    "model": "gpt-5",
    "messages": [...],
    "max_tokens": None,  # β GPT-5μ—μ„ null λ¶κ°€
}

# After (μμ •λ¨)
api_params = {
    "model": "gpt-5",
    "messages": [...],
}
# Noneμ΄ μ•„λ‹ λ•λ§ μ¶”κ°€
if max_output_tokens is not None:
    api_params["max_tokens"] = max_output_tokens
```

### 2. β `temperature` μ—λ¬
**μ¦μƒ:**
```
Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' 
does not support 0.5 with this model. Only the default (1) value is supported."}}
```

**ν•΄κ²°:**
```python
# Before (μ—λ¬ λ°μƒ)
api_params = {
    "model": "gpt-5",
    "messages": [...],
    "temperature": 0.5,  # β GPT-5λ” 1.0λ§ μ§€μ›
}

# After (μμ •λ¨)
api_params = {
    "model": "gpt-5",
    "messages": [...],
}
# GPT-5κ°€ μ•„λ‹ λ•λ§ temperature μ¶”κ°€
if not model.startswith("gpt-5"):
    api_params["temperature"] = 0.5
```

## GPT-5 API μ μ•½μ‚¬ν•­

### μ§€μ›λμ§€ μ•λ” νλΌλ―Έν„°

| νλΌλ―Έν„° | GPT-4 | GPT-5 | λΉ„κ³  |
|---------|-------|-------|------|
| `temperature` | β… 0.0~2.0 | β οΈ 1.0λ§ μ§€μ› | λ‹¤λ¥Έ κ°’ μ‚¬μ© μ‹ 400 μ—λ¬ |
| `max_tokens` | β… μ„¤μ • κ°€λ¥ | β… μ„¤μ • κ°€λ¥ | `null` μ „λ‹¬ μ‹ 400 μ—λ¬ |
| `top_p` | β… 0.0~1.0 | β“ ν™•μΈ ν•„μ” | |
| `presence_penalty` | β… -2.0~2.0 | β“ ν™•μΈ ν•„μ” | |
| `frequency_penalty` | β… -2.0~2.0 | β“ ν™•μΈ ν•„μ” | |

### Chat API vs Responses API

**Chat API** (`chat.completions.create`):
- GPT-4o, GPT-4, GPT-3.5 λ“±μ—μ„ μ‚¬μ©
- ν‘μ¤€ νλΌλ―Έν„° μ§€μ›

**Responses API** (`responses.create`):
- GPT-5 μ „μ© (Labelerμ—μ„ μ‚¬μ©)
- λ‹¤λ¥Έ μ…λ ¥/μ¶λ ¥ κµ¬μ΅°
- `reasoning`, `text` νλΌλ―Έν„° μ‚¬μ©

## μμ •λ μ½”λ“

### `chat/engine.py`
```python
async def generate(
    self,
    conversation: ConversationState,
    user_message: ChatMessage,
    metadata: dict[str, Any],
) -> list[ChatMessage]:
    prompt_messages = list(self._build_prompt(conversation, user_message))
    
    # Build API call parameters
    api_params: dict[str, Any] = {
        "model": self._config.model,
        "messages": prompt_messages,
    }
    
    # GPT-5 only supports default temperature (1.0)
    # For other models, include temperature if specified
    if not self._config.model.startswith("gpt-5"):
        api_params["temperature"] = self._config.temperature
    
    # Only include optional parameters if they are not None
    if self._config.top_p is not None:
        api_params["top_p"] = self._config.top_p
    if self._config.max_output_tokens is not None:
        api_params["max_tokens"] = self._config.max_output_tokens
    if self._config.presence_penalty is not None:
        api_params["presence_penalty"] = self._config.presence_penalty
    if self._config.frequency_penalty is not None:
        api_params["frequency_penalty"] = self._config.frequency_penalty
    
    try:
        response = await self._client.chat.completions.create(**api_params)
    except OpenAIError as exc:
        raise RuntimeError("OpenAI chat completion failed") from exc
    return self._to_chat_messages(response, metadata)
```

### `models/settings.py`
```python
class Settings(BaseSettings):
    # ...
    OPENAI_MODEL: str = "gpt-5"
    OPENAI_TEMPERATURE: float = 1.0  # GPT-5 only supports default (1.0)
    OPENAI_TOP_P: float | None = None
    OPENAI_MAX_OUTPUT_TOKENS: int | None = None
    # ...
```

## ν™κ²½ μ„¤μ •

### `.env` νμΌ
```bash
# GPT-5 μ‚¬μ© μ‹
OPENAI_API_KEY=your_gpt5_api_key
OPENAI_MODEL=gpt-5
OPENAI_TEMPERATURE=1.0  # λ°λ“μ‹ 1.0

# GPT-4o μ‚¬μ© μ‹ (fallback)
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.7  # μ›ν•λ” κ°’ μ„¤μ • κ°€λ¥
```

## λ¨λΈ μ „ν™ κ°€μ΄λ“

### GPT-5 β†’ GPT-4o μ „ν™
```bash
# .env μμ •
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.7
LABELER_MODEL=gpt-4o
```

μ„λ²„ μ¬μ‹μ‘:
```bash
cd backend
uv run python -m uvicorn app.main:app --reload --port 8000
```

### GPT-4o β†’ GPT-5 μ „ν™
```bash
# .env μμ •
OPENAI_MODEL=gpt-5
OPENAI_TEMPERATURE=1.0  # ν•„μ!
LABELER_MODEL=gpt-5
```

## λ””λ²„κΉ… ν

### μ—λ¬ λ΅κ·Έ ν™•μΈ
```python
# 400 μ—λ¬ λ°μƒ μ‹ μ „μ²΄ μ”μ²­ λ΅κΉ…
import logging
logging.basicConfig(level=logging.DEBUG)

# OpenAI λΌμ΄λΈλ¬λ¦¬ λ””λ²„κ·Έ λ¨λ“
import openai
openai.log = "debug"
```

### API νλΌλ―Έν„° κ²€μ¦
```python
# engine.pyμ— μ„μ‹ λ΅κΉ… μ¶”κ°€
print(f"[DEBUG] API params: {api_params}")
response = await self._client.chat.completions.create(**api_params)
```

### λ¨λΈλ³„ λ¶„κΈ° ν™•μΈ
```python
if self._config.model.startswith("gpt-5"):
    print("[DEBUG] Using GPT-5 mode (no temperature)")
else:
    print(f"[DEBUG] Using GPT-4 mode (temperature={self._config.temperature})")
```

## ν…μ¤νΈ

### λ‹¨μ„ ν…μ¤νΈ
```bash
cd backend
uv run pytest tests/test_agent_tools.py -v
```

### ν†µν•© ν…μ¤νΈ (Chat)
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Hello!",
    "conversation_id": null
  }'
```

### Agent μ—”λ“ν¬μΈνΈ ν…μ¤νΈ
```bash
curl -X POST http://localhost:8000/agent/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Test GPT-5",
    "conversation_id": null
  }'
```

## κ²°λ΅ 

β… **μμ • μ™„λ£:**
- `max_tokens=null` μ—λ¬ ν•΄κ²°
- `temperature` GPT-5 νΈν™μ„± μ¶”κ°€
- μ΅°κ±΄λ¶€ νλΌλ―Έν„° μ „λ‹¬λ΅ GPT-4/GPT-5 λ¨λ‘ μ§€μ›

β… **μ•μ „ν• κΈ°λ³Έκ°’:**
- `OPENAI_TEMPERATURE=1.0` (GPT-5 κΈ°λ³Έκ°’)
- Optional νλΌλ―Έν„°λ” NoneμΌ λ• μ „λ‹¬ν•μ§€ μ•μ

β… **ν•μ„ νΈν™μ„±:**
- GPT-4oλ΅ μ „ν™ μ‹μ—λ„ μ •μƒ μ‘λ™
- ν™κ²½λ³€μλ§ λ³€κ²½ν•λ©΄ λ¨

μ΄μ  GPT-5 Chat APIλ¥Ό μ‚¬μ©ν•  λ• νλΌλ―Έν„° κ΄€λ ¨ μ—λ¬κ°€ λ°μƒν•μ§€ μ•μµλ‹λ‹¤! π‰
